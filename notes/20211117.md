# Machine learning for privacy, privacy for machine learning

-> Bulk of information on PDF slides

- Idea: Evaluate privacy by pretending to be adversary
- Machine learning: Can be used by adversary to gain information from large
  amount of data

## Biomedical data studies in research

- Genomic variants:
  - Dimension consequence of those locations which actually
    differ between individuals
  - Data type is homozygotic (wt, mut), heterozygotic (I guess ?)

## Interdependent privacy

- Problem: Genetic information hereditary. Information about person A yields
  information about their relatives.

## Quantifying genomic privacy

- Hat variables: Predictions (I guess ?)

## Matching of miRNA

- Two datasets not linked to each other. Rather linking between miRNA profiles
  within one data set, that is for a given profile find another profile (from a
  different time) of the same human
