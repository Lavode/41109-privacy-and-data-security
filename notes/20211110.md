# Differential privacy

Sanitiation algorithm `M: X^n -> Y`.

Necessarily randomized, to achieve differential privacy:
Two neighbouring datasets X^n, X'^n, that is they differ in at most one entry.

## Definition differential privacy

M has epsilon-differential privacy iff:

```
For all Y' \subset Y, forall X^n ~ X'^n (neighbouring):

P[M(X^n) \in Y] / P[M(X'^n) in Y] <= e^epsilon
```

### Remark

- Epsilon privacy parameter, smaller epsilon is more private
  Usually in range `[0.1, 5]` to be considered adequate
- One entry in dataset affects every output at most by factor of e^epsilon
- M must be randomized
- DP is symmetric in X, X'
- Reason for using e^epsilon: Additive privacy measure, as then (proof follows)
  `e^{eps_1} * e^{eps_2} = e{eps_1 + eps_2}`

## Implementing in practice

- Trusted party running M
- Or maybe MPC, but not topic here
- Compare randomised response algorithm from last lecture: That one was run
  locally by each (untrusted) participant `x_i`
  -> "Local differential privacy". More private!
- Advantage of this model: Algorithm can take full dataset into account, rather
  than having to work with only one data point at a time. Better accuracy (=
  less noise for same privacy level) with centralied model.
- Clients always assumed to be honest. In either model they could provide fake
  data anyway, them applying a local DP algorithm incorrectly is no big deal
  then.

## Randomized response is DP

Let
- `X_i \in {0, 1}`
- `Y_i = {X_i with probability alpha, R_i with probability (1 - alpha)}` 
- where `R_i <- {0, 1}`

Then, for neighbouring datasets `X^n, X'^n` differing in `x_j != x'_j`,
with `Y^n = M(X^n)`, `Y'^n = M(X'^n)`:
```
P[M(X^n) = y^n] / P[M(X'^n) = y^n]
= Product(P[Y_i = y_i]) / Product(P[Y'_i = y_i])
= P[Y_j = y_j] \ P[Y'_j = y_j] # As only differing element
```

Recall:
```
P[Y_j = 0] = alpha * P(x_j = 0) + (1 - alpha) * 1/2
           <= 1/2 + alpha/2
```

And also:
```
P[Y_j = 0] >= 1/2 - alpha/2
```

As such:
```
P[M(X^n) = y^n] / P[M(X'^n) = y^n]
<= (1/2 + alpha/2) / (1/2 - alpha/2)
= (1 + alpha) / (1 - alpha)
=~ e^(2*alpha) // as 1+x =~ e^x for small x
```

Hence: Randomised resopnse is approximately `2*alpha`-differentially private.

## Laplace mechanism

Goal: Generate noise. For randomized response we picked from a uniform
distriubtion, but not suitable for real-valued data points.

Here: `M : X^n -> Y^k`
- Though often just `k = 1` and `Y = R`

`f: X^n -> R` arbitrary query function.
`N \in R` random noise
`M(X^n) = f(X^k) + N`

### How to pick noise N?

- Should have mean 0, to not influence mean of sanitized dataset
- For neighbouring `X^n, X'^n`, let:
  `Delta = |f(X^n) - f(X'^n)|`
- For DP it must hold:
  ```
  P[N = y] / P[N = y + Delta] <= e^epsilon
  ```
- Maximum Delta for two neighbouring datasets:?

### L1-sensitivity

L1-sensitivity of a query function `f: X^n -> R^k` is:
```
Delta^(f) = max (over neighbouring pairs X^n, X'^n) ||f(X^n) - f(X'^n)||_1
```

#### Example

```
X^n = {0, 1}^n
f(X^n) = mean(X^n)

Then:
Delta^(f) = 1/n
```

N should ensure that changing the output by at most delta, change the
probability ratio by at most e^epsilon.

### Def Laplace distribution

A random value X in R with PDF:
```
p(x) = 1/(2b) * e^(- |x|/b)
```

has Laplace distribution with parameter b.

```
X ~ Lap(b)
Var[X] = 2b^2
```

### Def Laplace mechanism

The Laplace mechanism for `M: X^n -> R^k` and query function `f: X^n -> R^k`
is:

```
M(X^n) = f(X^n) + [N_1, ..., N_k]
N_i ~ Lap(Delta/epsilon) IID
```

Where Delta is sensitivity of f.

#### Example

```
f(X^n) = mean(X^n)

M(X^n) = f(X^n) + Lap(Delta/epsilon) = f(X^n) + Lap(1/(epsilon * n))
That is b = 1/(epsilon * n)

Then:
E[Y] = E[f(X^n)]
Var[N] = 2/(epsilon^2 * n^2) // 'Pollutes' signal
```

### Theorem

Laplace mechanism for k-dimensional queries and `epsilon > 0` is
epsilon-differentially-private.

#### Proof

Let `X^n`, `X'^n` neighbouring datasets. Let `P(X = Y^k)` and `P(X' = Y^k)` be
PDF of `M(X^n)` and `M(X'^n)` respectively.

Then:

```
P(X = Y^k) / P(X' = Y^k) = (product exp(-epsilon * |f(x)_j - y_j| / Delta)) / (product exp(-epsilon * |f(x'_j) - y_j| / Delta))
= product exp(-epsilon / delta * (|f(x)_j - y_j| - |f(x')_j - y_j|))
<= product exp(-epsilon / delta * (|f(x')_j - f(x)_j|)) // Triangle inequality
= exp(sum( epsilon / delta * |f(x)_j - f(x')_j|))
= exp(epsilon / delta * ||f(x)_j - f(x')_j||_1)
<= exp(epsilon / delta * delta) // Properties of L1 sensitivity (?)
= exp(epsilon)
```

#### Example: Counting queries

Let `f` be counting query, e.g. `f(X^n) = |{x \in X^n : x = i}|`, where `i`
valid value of `X`

Then: `Delta^(f) = 1` - changing one value will change count by at most 1.
As such: 2-DP version of counting is:
```
f(X^n) + Lap(1/epsilon)
```

#### Example: Histogram

Let `f` be histogram with k bins: `f : X^n -> R^k, x^n -> [H_1, ..., H_k]`
NB histograms themselves theoretically over natural numbers, but we'll use
reals as we'll use real-valued noise.

Where `H_j` counts number of `x \in X` with some property

L1-sensitivity of `f` is `2`, as, at most, one item moves from one histogram
bin to another.

Thus:
```
Y = f(X^n) + [N_1, ..., N_k]
N_j ~ Lap(2/epsilon)
```

Then `Y` is an epsilon-DP histogram.

## Properties of DP

- Postprocessing preserves DP:
  `M: X^n -> Y`. Postprocessing `A: Y -> Z` any randomised function.
  If M is epsilon-DP, then A(M) is epsilon-DP

  [ Proof in lecture notes ]
